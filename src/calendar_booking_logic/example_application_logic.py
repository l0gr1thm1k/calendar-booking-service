from typing import List

def tokenize_text(text: str) -> List[str]:
    return text.split()
